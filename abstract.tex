\chapter*{}
%\thispagestyle{empty}
\vspace{-3cm}
\noindent
\begin{center}
{\large \sffamily \textbf{Abstract}}
\end{center}
\noindent


Grasping is one of the most fundamental skills of manipulation. Mastering grasping is a precondition of performing complex manipulation tasks for robots. Although robotic grasping has been studied over a long period, there still remains a big gap when compared to the capability of human grasping. Especially in an unstructured environment, the robot is confronted with many challenges. First, grasping is usually related to a task intention. For example, how to select a suitable grasp configuration to satisfy a task constraint is not trivial. In addition, due to the variety of objects existing in the world, it is unfeasible and impracticable to model every individual object a-priori. Thereafter, grasping objects which are presented to robots for the first time is another task that must be tackled. Moreover, the imperfection of sensors used for grasping generate inaccurate measurements. Focus must be undertaken with regards to dealing with the uncertainty of a perceptual system for grasping. People may ask: why is grasping such a difficult task for robots when humans can master the grasping skill at such an early age? One must accept that grasping is comprised of an interdisciplinary set of skills. These include the requirement to perceive the surrounding environment plus objects, decide upon a feasible grasping strategy and finally execute the control of the grasping process. 

In this dissertation, an integrated system for grasping is proposed. The system regards grasping as a dynamic process, from the state an object is perceived to the state the object is grasped. A mobile manipulator which uses the proposed system is able to perform robust grasping under various levels of prior knowledge and conditions. The prior knowledge and conditions determine the major problem to be solved in a specific grasp scenario. 

I propose to represent the diveristy of various grasping scenarios under a unified model which is defined by `Bayesian Network'. In this way, the grasping problem is approached in a probabilistic fashion. The model defines a joint distribution of grasping relevant factors, while the uncertainty of these factors is quantified by probabilistic distributions. Three challenging grasping scenarios under predefined conditions are formulated by the proposed model. The difference between the scenarios is encoded by conditioning respective factors in this model. 

In the first scenario, grasping is addressed in the context of assembly tasks. The major problem is to select grasp configurations which maximize the probability of satisfying task constraints. A skill framework is proposed to generate a complete sequence for a mobile manipulator to perform an assembly. This ranges from object perception, to the reasoning of grasp strategy to the control of robot motions. The framework provides an intuitive way for a non-expert user to parameterize an assembly problem. Within the framework, high level skills are proposed to perform pick-and-place actions to alter the orientation of objects as well as insertion actions for assembling two objects. Successful execution of both tasks requires that the objects should be grasped in an assignment preferred orientation. Different from previous works which only consider gripper orientation to fulfill this requirement, my method is able to generate complete robot configurations for the purpose of reducing both the total traveling distance and the task execution time. This combined with modeling arm-platform coordination in the framework, further increase the efficiency and robustness of executing the given task. 

In the second scenario, grasping of unknown objects is addressed. Here the challenge lies in synthesizing a grasp configuration which maximizes the probability of force closure. For this purpose, a new probabilistic object representation plus sensor fusion method is applied to reconstruct the shape of objects prior to grasping. This approach is especially suitable for modeling objects with irregular forms. Different from previous works which use other representations, my proposal can model the reconstruction uncertainty based on the noise model of sensors. In this way, this representation has a correct interpretation of the modeling uncertainty and can be used to penalize grasp points on uncertain areas. Utilizing this form of representation, a grasp synthesis method based on simulated annealing is proposed to search for an appropriate grasp configuration. Compared with the state-of-the-art method that uses a similar representation, my method works on 3D objects and and is more computationally efficient.

In the third scenario, a sensor with a large uncertainty is used to study grasping performance. The major challenge is how to perform robust grasping even when given a large perceptual uncertainty. Different from previous approaches which usually execute grasp in open loop, an adaptive control architecture is proposed. It allows a robot to perform grasping in a closed-loop fashion. Using the proposed architecture, the perceptual result is continuously fed back to the grasp synthesis module in which current grasp configurations 
are generated. Motion adaptation to the new grasp configuration is achieved by Dynamic 
Movement Primitives (DMP) such that during the approaching phase, uncertainty of perception is actively reduced. Actuators of a mobile manipulator can be combined gracefully and used purposefully in different phases to improve the overall grasping process. 

This research lays the foundation of how to approach the grasping problem in a probabilistic and systematic fashion. When compared to previous works which often consider one grasping phase, this work provides an end-to-end solution and closes the perception-action loop for the entire grasping process. My work provides the infrastructure for future research directions and paves the way toward realizing human-level dexterous grasping. 



%\vspace{0.5cm}
%\selectlanguage{ngerman}%Babel umschalten
%\noindent
%\begin{center}
%{\large \sffamily \textbf{Zusammenfassung}}
%\end{center}
%\noindent
%...
%
%\selectlanguage{american} %Babel zurücksetzen
