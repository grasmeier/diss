% chapter introduction 

\chapter{Introduction}

\section{Challenges}


\section{Main Contributions and Outline of this Thesis}
In this dissertation, a general framework on robotic grasping is developed. The framework provides mobile manipulation systems the capability to conduct a wide range of grasping and manipulation tasks. In our work, we consider grasping as a whole process, which can be divided into three phases in the order of time: pre-grasp phase, grasp motion phase and force closure phase. A perception-planning-control loop is involved in each of these phases. Our framework contains a set of  methods to handle the problems in the perception-planning-control loop during the whole grasping process systematically. One major problem to overcome in grasping is handling uncertainty. On one side, the framework aims to model the uncertainty probabilistically to provide object state as a distribution to the system, on the other side our framework provides methods for actively exploration and tracking which help to reduce the uncertainty. Differ from the previous work, the framework itself creates a new paradigm to solve grasping as a whole. A short overview and the contributions of the methods we propose in the framework can be summarized in the following aspects. 


\subsubsection{Probabilistic Modelling and Maximization of Grasping Success}
Uncertainty of the real world, unknown dynamics of objects and error in a perceptional system makes a robot difficult to guarantee that a grasp action will  always lead to a success. To manage the complexity and uncertainty in the real world, modelling the success probability of a grasping action is a promising method to handle these problems. In Chapter 3 we describe a probabilistic approach to model the grasping process. The success probability is calculated based on a model of conditional grasping success and a model of object posterior. This method reduces the complexity of directly modelling the grasp success probability. It splits a complex modelling problem into two independent models which are not correlated with each other. The conditional grasp success model describes the probability of success by taken an grasp action, under the condition that the object state is given. It is modelled using four criteria, which maps the principle of underlying grasp physics, actuation uncertainty, representation uncertainty and a task  affordance to the model. Object posterior models the object state distribution after a series of observations are conducted. Depending on the choice of the representation, for some real world objects whose shape can be approximated by a group of shape primitives, the dimension of the object state space is small. The object posterior of these objects can be computed by e.g. Bayes filtering. For most real  world objects, the dimension of state space is large because of their individual courses of the surface, we propose a new surface representation and fusion method to compute the posterior. The underlying structure of the surface representation is a variance augmented signed distance function. This representation allows temporal and spacial fusion by multiple depth cameras with  individual noise characteristics. The result of the sensor fusion is a uncertainty-aware surface distribution which approximate the object posterior. After modelling the grasp success probability, the aim  is to search for a grasp action that maximizes the success probability. For this purpose, we propose a Monte Carlo based method to find an optimal grasp trajectory. This method seamlessly connects grasp perception and grasp control in a systematic way, while serves as a foundation for grasping unknown objects. The computational time of our method performs 30 times faster than the state-of-the-art. Experimental results verifies a significant grasping accuracy improvement in the scenario of  grasping real world unknown objects by using the proposed method. 


\subsubsection{Arm-platform Coordination Enables Realizing Grasping Strategy and Efficient Mobile Manipulation}
Mobile manipulators are the robots which typically equipped with a mobile base platform for navigation and arm(s) for manipulation. For reach-and-grasp tasks, state-of-the-art approaches consider it as two isolated problems: a navigation problem followed by a motion planning problem. Using these approaches a robot should first move with mobile platform to a location that the object is reachable, then use its manipulator to accomplish the object grasping task. Although it is a feasible solution, the time used to perform this task is not efficient. In contrast, a human performs the same task with all his actuation capability (arm, hand, body, locomotion) in a coordinated manner. In chapter 4, inspired by the human, we propose to bridge the gap between human reach-and-grasping and robotic reach-and-grasping by arm-platform coordination. In this chapter, an analysis of the reachability of a mobile manipulator is first conducted. The result revealed that the overlap between the workspace of a manipulator with the observation space of a fixed mounted camera is very limited. As a result, a mobile manipulator has to usually face the following dilemma, the target object is located in the field of view of the robot, but it is not reachable from the robot manipulator, or the object is reachable from the manipulator but lies out of the field of view of the robot. This implies that arm-platform coordination is the only promising approach to  efficiently solve the reach-and-grasping problem. To enable a mobile manipulator to move with its whole degree of freedom (DOF), we propose a concept of virtual joints, and add another kinematic structure by composing the virtual joints and the manipulators' joints into a common kinematic chain. In this way, the planning of the arm-platform coordinated motion can be seamless integrated into an existing motion planning framework. We demonstrate the benefits of this concept in two problems: grasp strategy planning and assembly task planning. In grasp strategy planning, we propose to design several strategies for the grasping process. Some are indented for reducing perceptual uncertainty, others are better for increasing grasp efficiency. A strategy selection algorithm based on Markov Decision Process is proposed to handle which strategy should be selected. In assembly task planning, two high-level assembly skills are designed to encapsulate low-level perception and motion planning tasks. A base-position planning algorithm based on iterative inverse kinematic is proposed to compute the optimal base placement to solve the aforementioned dilemma. The concept of arm-platform coordination allows a complex grasp strategy being executable in the strategy planning problem while improves the task efficiency for complex assembly problems.   


\subsubsection{Boosting Grasping Robustness and Flexibility by an Adaptive Control Architecture}
After the concept of arm-platform coordination is introduced in chapter 4. Chapter 5 addresses the control aspect of the grasping process. In general, individual actuators of a mobile manipulator are usually controlled by their independent interface. However, arm-platform coordination requires control commands to be sent to each actuator simultaneously. To control the individual actuators in synchrony, we propose a system control architecture, which enables a plug-in mechanism to combine arbitrary independent actuators into a common control loop in a flexible manner. This allows a mobile manipulator to easily switch and combine the actuators according to the requirements of a grasping phase. For example, a mobile manipulator can use arm-platform coordination in the pre-grasp phase for moving to a reachable position and for interacting with an object. Motions executed by arm alone can be used in the grasp-motion phase for approaching a grasp configuration. Arm-gripper coordination can be exploited in the force-closure phase for stabilizing the object within the gripper. 

In the most state-of-the-art grasping approaches, motions of the grasping are usually pre-planned. Thus, adaptation of the grasp motion to the change of the object state is not possible. We propose to solve this problem by an online trajectory generation algorithm and feed the state of the object back to the trajectory generator. In this way, a large control loop is closed for the system. Using the proposed method, a mobile manipulator is not only able to reason about the grasp configuration  but also recognize the change of the environment and adapt to the change. As a result, the robustness of the grasping accuracy is significant improved. 

 

